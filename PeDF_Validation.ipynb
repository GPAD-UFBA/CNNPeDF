{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import *\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We've already made 0 importation.\n",
      "We've already made 1000 importation.\n",
      "We've already made 2000 importation.\n",
      "We've already made 3000 importation.\n",
      "We've already made 4000 importation.\n",
      "4180\n"
     ]
    }
   ],
   "source": [
    "whole_data = []\n",
    "\n",
    "# loop from 0 to the number of .hdf5 files you want to load\n",
    "nb_files = 4180\n",
    "\n",
    "for i in range(0,nb_files):\n",
    "    # Selects the file\n",
    "    file_to_load = 'h5/n2data_extended_ballroom_' + str(i) + '.hdf5'\n",
    "    \n",
    "    # Gets data\n",
    "    data = data_loader(file_to_load)\n",
    "    whole_data.append(data)\n",
    "    if i%1000 == 0:\n",
    "            print(f\"We've already made {i} importation.\")\n",
    "\n",
    "    \n",
    "print(len(whole_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "O database possui 4180 exemplos de treinamento.\n",
      "O nível Wavelet A2 tem 149 amostras.\n",
      "O nível Wavelet D2 tem 149 amostras.\n",
      "O nível Wavelet D1 tem 298 amostras.\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "# LIST -> Dictionary(Data) -> Features(numpy.ndarray)\n",
    "# m -> the m-th example\n",
    "# feature -> ODF_SET, PeDF_FULL_SET, PeDF_PARTIAL_SET, coeffs\n",
    "# wavelet_level -> wavelet level\n",
    "# whole_data[m][feature][wavelet_level]\n",
    "\n",
    "print(type(whole_data[0]['ODF_SET'][0]))\n",
    "\n",
    "print(f\"O database possui {len(whole_data)} exemplos de treinamento.\")\n",
    "print(f\"O nível Wavelet A2 tem {len(whole_data[0]['PeDF_PARTIAL_SET'][0])} amostras.\")\n",
    "print(f\"O nível Wavelet D2 tem {len(whole_data[0]['PeDF_PARTIAL_SET'][1])} amostras.\")\n",
    "print(f\"O nível Wavelet D1 tem {len(whole_data[0]['PeDF_PARTIAL_SET'][2])} amostras.\")\n",
    "\n",
    "print(whole_data[0]['bpm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O valor máximo de andamento é 216.\n",
      "O valor mínimo de andamento é 65.\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# CRIANDO VETOR PRÓPRIO Y\n",
    "y = []\n",
    "for j in range(0,len(whole_data)): \n",
    "    y.append(whole_data[j]['bpm'])\n",
    "    \n",
    "print(f\"O valor máximo de andamento é {np.max(y)}.\")\n",
    "print(f\"O valor mínimo de andamento é {np.min(y)}.\")\n",
    "#print(y)\n",
    "y = np.array(y).reshape(len(whole_data),1)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(whole_data[0]['PeDF_PARTIAL_SET'][2][0])\n",
    "lista = []\n",
    "\n",
    "for j in range(0,len(whole_data)):  #varrer m-exemplos\n",
    "\n",
    "    listaux0 = []    #D1\n",
    "    listaux1 = []    #D2\n",
    "    listaux2 = []    #A2\n",
    "    listaux0.append(1)\n",
    "    listaux1.append(1)    \n",
    "    listaux2.append(1)  \n",
    "    for i in range(1,len(whole_data[0]['PeDF_PARTIAL_SET'][2])):\n",
    "        if (i<len(whole_data[j]['PeDF_PARTIAL_SET'][2])-1):\n",
    "            if (whole_data[j]['PeDF_PARTIAL_SET'][2][i]>whole_data[j]['PeDF_PARTIAL_SET'][2][i-1] and whole_data[j]['PeDF_PARTIAL_SET'][2][i]>whole_data[j]['PeDF_PARTIAL_SET'][2][i+1]):\n",
    "                listaux0.append(whole_data[j]['PeDF_PARTIAL_SET'][2][i])\n",
    "            else:\n",
    "                listaux0.append(0)\n",
    "        else: \n",
    "            listaux0.append(0)\n",
    "\n",
    "    for i in range(1,len(whole_data[0]['PeDF_PARTIAL_SET'][1])):\n",
    "        if (i<len(whole_data[0]['PeDF_PARTIAL_SET'][1])-1):\n",
    "            if (whole_data[j]['PeDF_PARTIAL_SET'][1][i]>whole_data[j]['PeDF_PARTIAL_SET'][1][i-1] and whole_data[j]['PeDF_PARTIAL_SET'][1][i]>whole_data[j]['PeDF_PARTIAL_SET'][1][i+1]):\n",
    "                listaux1.append(whole_data[j]['PeDF_PARTIAL_SET'][1][i])\n",
    "            else:\n",
    "                listaux1.append(0)\n",
    "        else: \n",
    "            listaux1.append(0)\n",
    "        if (i<len(whole_data[0]['PeDF_PARTIAL_SET'][0])-1):\n",
    "            if (whole_data[j]['PeDF_PARTIAL_SET'][0][i]>whole_data[j]['PeDF_PARTIAL_SET'][0][i-1] and whole_data[j]['PeDF_PARTIAL_SET'][0][i]>whole_data[j]['PeDF_PARTIAL_SET'][0][i+1]):\n",
    "                listaux2.append(whole_data[j]['PeDF_PARTIAL_SET'][2][i])\n",
    "            else:\n",
    "                listaux2.append(0)\n",
    "        else: \n",
    "            listaux2.append(0)\n",
    "            \n",
    "#Setar shape 298, 149, 149 17x18 = 306 \n",
    "    for i in range(0,8):\n",
    "        listaux0.append(0)\n",
    "    for i in range(0,8+149):\n",
    "        listaux1.append(0)\n",
    "        listaux2.append(0)\n",
    "\n",
    "#\n",
    "    lista.append([listaux0, listaux1, listaux2]) #len = 3*306*4180 - 3837240 dados\n",
    "\n",
    "    \n",
    "lista = np.array(lista).reshape(len(whole_data),306,3) #(4180,3,306)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4190 exemplo\n",
    "#3 níveis wavelet\n",
    "#306 amostras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
